# -*- coding: utf-8 -*-
"""IA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lVQeVnuSulrltfg7qJBkqpJSm6eSrKTJ
"""

from ultralytics import YOLO
from datasets import load_dataset
import os
import cv2
import numpy as np
from google.colab.patches import cv2_imshow
from huggingface_hub import login # Import the login function from huggingface_hub

# Authenticate with your Hugging Face token
login() # This will prompt you to enter your token if you haven't already logged in.

# Carregar o dataset
dataset = load_dataset("gabraken/mtg-detection")

# Exibir informações do dataset
print(dataset)

# Selecionar uma amostra do dataset
sample = dataset['train'][20]

# Carregar a imagem
image = cv2.imdecode(np.frombuffer(sample['image'], np.uint8), cv2.IMREAD_COLOR)

# Exibir a imagem
cv2_imshow(image)

# Exibir anotações
print(sample['annotation'])

import os
import cv2
import numpy as np

# Criação de diretórios
os.makedirs('datasets/data/images/train', exist_ok=True)
os.makedirs('datasets/data/labels/train', exist_ok=True)

# Função para converter pontos em bounding box (corrigida para lista de listas)
def points_to_bbox(points):
    xs = [p[0] for p in points if p[2]]  # x se visível
    ys = [p[1] for p in points if p[2]]  # y se visível
    if not xs or not ys:
        return None
    x_min, x_max = min(xs), max(xs)
    y_min, y_max = min(ys), max(ys)

    x_center = (x_min + x_max) / 2
    y_center = (y_min + y_max) / 2
    width = x_max - x_min
    height = y_max - y_min

    return x_center, y_center, width, height

# Função principal para salvar imagem e anotação
def convert_annotation(sample, idx):
    image = cv2.imdecode(np.frombuffer(sample['image'], np.uint8), cv2.IMREAD_COLOR)
    image_path = f'datasets/data/images/train/{idx}.jpg'
    cv2.imwrite(image_path, image)

    bbox = points_to_bbox(sample['annotation'])
    if bbox:
        x_center, y_center, width, height = bbox
        label_path = f'datasets/data/labels/train/{idx}.txt'
        with open(label_path, 'w') as f:
            f.write(f"0 {x_center} {y_center} {width} {height}\n")

# Aplicar para o conjunto de treino
for idx, sample in enumerate(dataset['train']):
    convert_annotation(sample, idx)

yaml_content = """
path: data  # pasta base
train: images/train
val: images/val

nc: 1  # número de classes (por exemplo, 1 se só detecta carta)
names: ["card"]
"""

with open("mtg.yaml", "w") as f:
    f.write(yaml_content)

from ultralytics import YOLO

model = YOLO("yolov8n.pt")
model.train(data="mtg.yaml", epochs=30, imgsz=640, batch=16)